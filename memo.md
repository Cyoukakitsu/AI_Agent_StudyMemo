# Week 1 学习笔记：提示工程的演进与未来

---

## 一、提示工程的演进与未来趋势

> **来源：** [YouTube: AI Prompt Engineering: A Deep Dive](https://www.youtube.com/watch?v=T9aRN5JkmL8)

提示工程并没有走向消亡，而是正在经历一场从"底层技术破解"到"高阶沟通与内省"的深刻演变。

### 1. 演进：从"技巧性黑客手段"到"高语境沟通"

- **技巧的消亡与模型的进化**：过去依赖特定"捷径"（如思维链），但这些技巧正被直接整合进模型训练，因此传统提示技巧注定是短命的。
- **从隐藏复杂性到给予充分信任**：过去倾向于简化任务防止模型崩溃；现在越来越多地提供完整上下文，甚至直接喂入整篇学术论文，因为 RLHF 模型已足够聪明。

### 2. 未来趋势一：模型成为提示词的"共创者"

- **高带宽人机协作**：用户提供初步想法或反馈，模型协助生成案例、调整结构，甚至编写用于指导其他模型的**元提示词（meta-prompts）**。
- 理想状态不是在文本框里输入指令，而是用户与模型之间进行高带宽的互动。

### 3. 未来趋势二：关系翻转——从"指挥临时工"到"接受专家访谈"

- **当下**：提示工程像在指导一个聪明但对公司一无所知的"外派临时工"，需要把所有细节和边缘情况解释清楚。
- **未来**：模型将扮演"专家设计师"角色，主动向用户提问、澄清需求，承担起"引导出（elicit）"用户真实意图的工作。

### 4. 未来趋势三：核心技能变成"内省"与"大脑外化"

- **清晰表达目标的需求永远存在**：从信息论角度，只要需要指定目标，某种形式的提示工程就永远存在。
- **内省（Introspection）成为关键技能**：挑战不再是如何"教"模型，而是如何搞清楚自己到底想要什么。
- **终极形态——"大脑外化"（Externalize your brain）**：本质上与哲学写作类似，将大脑中复杂、微妙的概念用绝对清晰的语言表达出来，让缺乏背景知识的实体完全理解。

> **总结**：提示工程的未来不是消失，而是剥离底层的"代码式调试"，上升为深度的自我内省、概念定义以及与超级智能进行高阶协同沟通的艺术。

---

## 二、OpenAI 内部使用 Codex 的最佳实践

> **来源：** The Art of Externalizing Your Brain: Advanced Prompt Engineering

关键不在于寻找神奇的单句提示技巧，而在于为模型提供**结构化的信息、充分的上下文以及迭代的空间**。

### 六大最佳实践

#### 1. 先规划，后执行（Start with Ask Mode）

- 大规模代码变更，先用 **提问模式（Ask Mode）** 生成实施计划。
- 再将计划作为输入，切换到 **代码模式（Code Mode）** 生成代码。
- 当前 Codex 最适合处理人类需约一小时、或需写几百行代码的任务。

#### 2. 像写 GitHub Issue 一样构建提示词

- 提供高度具体的结构化信息：相关文件路径、组件名称、代码差异（diffs）、文档片段。
- 常用句式：`"像在 [模块 X] 中那样实现这个功能"` ——为模型提供明确的参考锚点。

#### 3. 通过 AGENTS.md 提供持久的全局上下文

- 在代码仓库中维护 `AGENTS.md`，存放模型无法从代码本身推断的信息：命名规范、核心业务逻辑、已知代码怪癖（quirks）、隐藏的依赖关系。

#### 4. 迭代优化 Codex 的专属开发环境

- 配置启动脚本、环境变量、授予互联网访问权限。
- 出现构建错误时，应调整 **环境配置**，而不仅仅是修改代码。

#### 5. 灵活运用"N 中取优"（Best of N）

- 同时生成多个解决方案，审查不同迭代版本，将各响应中的优秀部分结合起来。

#### 6. 将任务队列作为"轻量级待办清单"

- 将稍纵即逝的想法、做了一半的工作直接"发射"到任务队列。
- Codex 作为"暂存区（staging area）"，在空闲时回顾处理。

### 内部团队实践案例

#### 前端团队：聚焦自动化与测试完善

- **夜间自动生成测试**：指向测试覆盖率较低的代码模块，第二天早上直接看到可运行的单元测试 PR。

#### API 团队：聚焦高可用性与工作流管理

- **加速事件响应**：值班时将崩溃的堆栈跟踪（stack trace）粘贴给 Codex，快速定位正确文件。
- **性能优化**：扫描重复且高成本的数据库调用，自动草拟批处理查询（batched queries）方案。
- **保持心流，异步处理琐碎任务**：发现小 Bug 时不中断当前工作，直接派发 Codex 任务，有空闲时再审查 PR；将 Slack 讨论线程、Datadog 追踪记录直接转发给 Codex 后台处理。
- **API 路由快速搭建**：通过提示词快速生成样板代码，如"搭建一个带有基本验证和日志记录的新 API POST 路由"。

> **总结**：前端团队利用 Codex 的自主性补充测试护城河；API 团队将其深度整合到高压的值班响应、复杂的性能调优以及对抗碎片化的异步任务处理中。模型已实质上成为不可或缺的"智能同事"。

---

## 三、斯坦福课程：现代软件开发者的职业建议

> **来源：** Stanford Slides — The Modern Software Developer

提示词工程被定义为 **"软件 3.0（Software 3.0）时代的通用语言（lingua franca）"**——既是让大模型执行任务的媒介，也是现代开发者"对模型进行编程"的核心方式。它兼具"艺术"与"科学"的双重属性。

### 核心技术矩阵（提示词的"科学"面）

| 技术 | 适用场景 | 说明 |
|---|---|---|
| **K-shot 提示** | 不需要太多推理的任务 | 提供 1/3/5 个示例指导模型 |
| **思维链（CoT）** | 多步逻辑的编程/数学任务 | 加入 `<reasoning>` 标签，展示推理过程 |
| **自洽性提示** | 减少幻觉和错误答案 | 多次采样并汇总最常见结果（模型集成） |
| **反思机制（Reflexion）** | 多轮迭代修正 | 追问"这个答案正确吗？请解释原因并重试" |

### 增强模型能力的外部手段

- **工具调用（Tool Use）**：允许大模型将任务推迟给外部系统，是减少幻觉和赋予自主性最重要的方法之一。
- **检索增强生成（RAG）**：为大模型注入额外上下文，获取最新知识、加快迭代、提供可解释性和来源引用。

### 最佳实践（提示词的"艺术"面）

1. **极致清晰度**：把提示词拿给缺乏背景的普通人看，如果他困惑，模型也会困惑。
2. **结构化格式**：使用类 XML 标签（如 `<log>`、`<error>`）清晰区分指令、日志信息和堆栈跟踪。
3. **明确且具象的约束**：指定编程语言、技术栈、依赖库及具体约束条件，不让模型去猜。
4. **拆解任务**：将复杂问题拆解为模型易于处理的多个子任务。
5. **积极运用角色提示**：通过系统提示词（System prompt）设定模型的"人格"和输出风格。

### 四个维度的职业核心建议

#### 1. 角色升级：向"人机协同工程师"转型

- AI 短期内将包揽 90% 的代码，并达到初级程序员水平。
- **成为技术主管（Tech Lead）**：不再是写代码的执行者，而是将编码任务委托给 AI、把控整体方向和质量的**"人机协同工程师（Human-agent engineering）"**。

#### 2. 培养核心护城河："代码品味（Good Taste）"

- 既然 AI 是主要"代码生成者"，人类工程师的核心工作就变成"代码审查者"。
- 培养鉴别力，辨别什么是好的软件、什么是坏的甚至错误的软件。
- **残酷的真相**：`LLM 的表现取决于你自身的水平`——如果你自己都无法理解代码库，LLM 也绝不可能理解。

#### 3. 专注于 AI 尚未取代的技能：业务理解

- AI 缺乏对真实世界商业逻辑的自发认知。
- **"业务理解（Business understanding）"**将成为比单纯写代码更有价值的竞争力：理解公司为什么做这个功能、用户的真实痛点是什么。

#### 4. 拒绝"凭感觉编程"，掌握系统性工具

- 这不是一门 **"凭感觉编程（vibe coding）"** 的课程，现代软件开发仍需严谨的工程思维。
- **积极尝试与探索（Experiment aggressively）**：目前 AI 辅助编程领域尚无固定模式，需要探索最适合自己的工作流。
- 核心技能：提供良好上下文、使用明确的结构化提示词、清晰表达约束条件、将复杂任务进行拆解。

> **核心论断**：你不会被 AI 取代，但你会被一个懂得如何使用 AI 的优秀工程师取代。
